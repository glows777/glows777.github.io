# 散列表-Hash Table
## 散列表概论
- 散列表又叫哈希表，Hash表
- 散列表两个核心问题是散列函数设计和散列冲突解决
### 散列思想
- 散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来
- 散列表用的借助数组支持按照下标随机访问的特性（时间复杂度是 O(1)），通过**散列函数**把元素的键值（key）映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。
## 散列函数
- 是一个函数，假设定义为`hash(key)`，key代表元素的键值，hash(key)代表经过散列函数计算得到的散列值
- 设计散列函数的三大准则
	- 散列函数计算得到的散列值是一个非负整数
	- 如果 key1 = key2，那 hash(key1) == hash(key2)
	- 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2) **->** 减少散列冲突
- 散列冲突
	- 意思就是两个不同的key经过散列函数(`hash(key)`)处理后，指向同一个槽（得到的结果是同一个散列值）
	- 因为数组的存储空间有限，所以会造成散列冲突，无法避免，但可以减少
	- 常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）
## 开放寻址法
### 核心思想
- 如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入
- 较为简单的探测方法 **->** 线性探测
- 开放寻址法的优点
	- 散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度。而且，这种方法实现的散列表，序列化起来比较简单。链表法包含指针，序列化起来就没那么容易
	- 在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。所以，使用开放寻址法解决冲突的散列表，装载因子的上限不能太大
	- 总结一下，当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因
### 线性探测
- 当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止（遍历到尾部还没有找到空闲的位置的话，那就再从表头开始找）![image](https://cdn.jsdelivr.net/gh/glows777/image-hosting@main/杂图/image.4vvxvg0x8s80.webp)（橙色的表示有数据，黄色表示空闲，x经过散列函数处理后为7，但7的位置已经有数据，所以一次往后查找）
- 查找数据 **->** 类似于插入 **->** 通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。
- 删除操作 **->**  删除操作有点特殊，不能单纯的将要删除的元素置空
	- 在查找的时候，一旦我们通过线性探测方法，找到一个空闲位置，我们就可以认定散列表中不存在这个数据。但是，如果这个空闲位置是我们后来删除的，就会导致原来的查找算法失效
	- 解决方法 **->**  我们可以将删除的元素，特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测
- 弊端
	-  当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度为 O(n)
	- 同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据
### 其他经典的探测方法
- 二次探测 **->**  所谓二次探测，跟线性探测很像，线性探测每次探测的步长是 1，那它探测的下标序列就是 hash(key)+0，hash(key)+1，hash(key)+2……而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 hash(key)+0，hash(key)+12，hash(key)+22……
- 双重散列 **->**  意思就是不仅要使用一个散列函数。我们使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置
### 装载因子
- 不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用**装载因子（load factor）来表示空位的多少**
- 计算公式 **->** `散列表的装载因子=填入表中的元素个数/散列表的长度`
## 链表法
- 链表法是一种更加常用的散列冲突解决办法
- 在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中 ![image](https://cdn.jsdelivr.net/gh/glows777/image-hosting@main/杂图/image.57j781zelqo0.webp)
- 插入数据 **->**  需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)
- 查找，删除数据 **->** 同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除 **->** 时间复杂度跟链表的长度k成正比，也就是O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数
### 改进链表法
- 将链表法中的链表改造为其他高效的动态数据结构，比如跳表、红黑树。这样，即便出现散列冲突，极端情况下，所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是 O(logn)，这样也就有效避免了前面讲到的散列碰撞攻击
- 总结一下，基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表
## HashTable的一些应用场景
### Word 文档中单词拼写检查功能
- 常用的英文单词有 20 万个左右，假设单词的平均长度是 10 个字母，平均一个单词占用 10 个字节的内存空间，那 20 万英文单词大约占 2MB 的存储空间，就算放大 10 倍也就是 20MB。对于现在的计算机来说，这个大小完全可以放在内存里面，所以可以使用散列表来存储整个英文单词词典
- 当用户输入某个英文单词时，我们拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示。借助散列表这种数据结构，我们就可以轻松实现快速判断是否存在拼写错误
### 有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序
- 将url作为key，访问次数作为value存入Hash Table中（如果key相同，则对应的value+1 **->** 访问次数+1），同时记录下访问次数的最大值k，时间复杂度为O(n)
- 如果k不是很大，那么用桶排序
- 如果k非常大，用快排
### 有两个字符串数组，每个数组大约有 10 万条字符串，如何快速找出两个数组中相同的字符串
- 首先，先遍历第一个数组，将每个字符串作为key,value作为出现次数存入Hash Table，然后遍历第二个字符串数组，以字符串为key在散列表中查找，如果value大于零，则说明存在相同的字符串。时间复杂度为O(n)
##  设计散列函数
- 散列表的查询速率不能直接定义为O(1),与散列函数，装载因子，散列冲突等都有关
### 拓展 **->** DocS攻击
- 在极端情况下，通过可以构造数据，使得所有的数据经过散列函数之后，都散列到同一个槽里。如果我们使用的是基于链表的冲突解决方法，那这个时候，散列表就会退化为链表，查询的时间复杂度就从 O(1) 急剧退化为 O(n)
- 如果散列表中有 10 万个数据，退化后的散列表查询的效率就下降了 10 万倍。
- 这样就有可能因为查询操作消耗大量 CPU 或者线程资源，导致系统无法响应其他请求，从而达到拒绝服务攻击（DoS）的目的。这也就是散列表碰撞攻击的基本原理
### 散列函数设计不宜复杂
- 过于复杂会消耗许多计算时间
- 散列函数生成的值要尽量随机并且均匀
### 关于装载因子的问题
- 如果太大，怎么办？
	- 对于静态（没有频繁插入删除数据），可以提前设计，这里不做讨论
	- 对于动态散列表，可以进行动态扩容 **->** 当散列表的装载因子超过某个阈值时，就需要进行扩容
	- 装载因子阈值的设置要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1
- 如何避免低效扩容？
	-  正常情况下，散列表插入一个数据很快，但是如果刚好这个数据卡在需要扩容的临界，那么会很费时 **->** 散列表的扩容，数据搬移操作很复杂，因为散列表的大小变了，数据的存储位置也变了，所以我们需要通过散列函数重新计算每个数据的存储位置
	- 解决方法 **->** 不采用一次性扩容机制 **->** 可以采用将扩容操作穿插在插入的过程中==分批完成==
	- 当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了
	- 在此期间，查询操作，会先从新的表里去查，然后在从老的表去查
	- Redis中的hash,set,hset,都是散列表实现，他们的动态扩容策略是同时维护两个散列表，然后一点点搬移数据
	- 这个思想类似于均摊法，将一次性扩容的时间均摊到每一次插入的时间中


## 总结
### 一个良好的散列表应该有什么特征
- 支持快速地查询、插入、删除操作
- 内存占用合理，不能浪费过多的内存空间
- 性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况
### 如何实现？
- 设计一个合适的散列函数
- 定义装载因子阈值，并且设计动态扩容策略
- 选择合适的散列冲突解决方法